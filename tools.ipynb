{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df925a82",
   "metadata": {},
   "source": [
    "Download template MNI-HCP which Tian atlas is defined in from templateflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e1d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from templateflow import api\n",
    "api.get('MNI152NLin6Asym', resolution=1, suffix='T1w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa3d2b",
   "metadata": {},
   "source": [
    "Plot tian atlas in different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56864e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from subcortex_visualization.plotting import plot_subcortical_data\n",
    "\n",
    "for s in [\"S1\", \"S2\"]:\n",
    "    plot_subcortical_data(atlas=f\"Melbourne_{s}\", hemisphere='both', cmap=\"hsv\")\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    fig.patch.set_facecolor('black')\n",
    "    ax.set_facecolor('black')         \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929dca14",
   "metadata": {},
   "source": [
    "Visualizing connectome matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f72488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from cmap import Colormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from nilearn.plotting import plot_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a80cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/temp_folder/dti/asjt/conn/tian_S3_conn.csv\", header=None)\n",
    "cm = Colormap('colorbrewer:OrRd_9')\n",
    "combined_cmap = LinearSegmentedColormap.from_list(\"\", cm(np.linspace(0, 1, 500)), N=1000)\n",
    "\n",
    "labels_fname = \"./data/Tian2020MSA/3T/Subcortex-Only/Tian_Subcortex_S3_3T_label.txt\"\n",
    "labels = np.loadtxt(labels_fname, dtype=str)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_matrix(df, labels=labels, cmap=combined_cmap, axes=ax, colorbar=True, vmax=0.9, vmin=0)\n",
    "\n",
    "for label in ax.get_xticklabels()[:25]:\n",
    "    label.set_color('lightgreen')\n",
    "for label in ax.get_yticklabels()[:25]:\n",
    "    label.set_color('lightgreen')\n",
    "\n",
    "for label in ax.get_xticklabels()[25:]:\n",
    "    label.set_color('lavender')\n",
    "for label in ax.get_yticklabels()[25:]:\n",
    "    label.set_color('lavender')\n",
    "\n",
    "fig.patch.set_facecolor('black')\n",
    "ax.set_facecolor('black')          \n",
    "\n",
    "# Make grid lines white for visibility (optional)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_color('white')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d902b2",
   "metadata": {},
   "source": [
    "Convert dataset into BIDS (anat and func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055da28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "fMRI_path = \"/Volumes/Extreme_SSD/payam_data/antinomics_data/fMRI\"\n",
    "sMRI_path = \"/Volumes/Extreme_SSD/payam_data/antinomics_data/sMRI_T1\"\n",
    "bids_path = \"/Volumes/Extreme_SSD/payam_data/antinomics_data/BIDS\"\n",
    "\n",
    "# Create BIDS dataset folder if it doesn't exist\n",
    "os.makedirs(bids_path, exist_ok=True)\n",
    "\n",
    "# Create minimal dataset_description.json\n",
    "import json\n",
    "dataset_description = {\n",
    "    \"Name\": \"My fMRI/sMRI Dataset\",\n",
    "    \"BIDSVersion\": \"1.8.0\",\n",
    "    \"DatasetType\": \"raw\"\n",
    "}\n",
    "with open(os.path.join(bids_path, \"dataset_description.json\"), \"w\") as f:\n",
    "    json.dump(dataset_description, f, indent=4)\n",
    "\n",
    "# Helper to zero-pad subject IDs\n",
    "def sub_id(idx):\n",
    "    return f\"sub-{idx:02d}\"\n",
    "\n",
    "# List of subjects based on sMRI filenames\n",
    "subjects = [f.replace(\".nii.gz\", \"\") for f in sorted(os.listdir(sMRI_path)) if f.endswith(\".nii.gz\")]\n",
    "\n",
    "for i, subj_name in enumerate(subjects, start=1):\n",
    "    sub_folder = os.path.join(bids_path, sub_id(i))\n",
    "    \n",
    "    # Create anat folder\n",
    "    anat_folder = os.path.join(sub_folder, \"anat\")\n",
    "    os.makedirs(anat_folder, exist_ok=True)\n",
    "    \n",
    "    # Copy T1 (anat)\n",
    "    t1_src = os.path.join(sMRI_path, f\"{subj_name}.nii.gz\")\n",
    "    t1_dst = os.path.join(anat_folder, f\"{sub_id(i)}_T1w.nii.gz\")\n",
    "    shutil.copy(t1_src, t1_dst)\n",
    "    \n",
    "    # Create func folder\n",
    "    func_folder = os.path.join(sub_folder, \"func\")\n",
    "    os.makedirs(func_folder, exist_ok=True)\n",
    "    \n",
    "    # Copy fMRI scans from all session folders into runs\n",
    "    run_counter = 1\n",
    "    for session_folder in [\"s1\", \"s2\"]:\n",
    "        func_src_folder = os.path.join(fMRI_path, session_folder)\n",
    "        func_files = [f for f in os.listdir(func_src_folder) if f.startswith(subj_name) and f.endswith(\".nii.gz\")]\n",
    "        for func_file in sorted(func_files):\n",
    "            func_src = os.path.join(func_src_folder, func_file)\n",
    "            func_dst = os.path.join(func_folder, f\"{sub_id(i)}_task-rest_run-{run_counter:02d}_bold.nii.gz\")\n",
    "            shutil.copy(func_src, func_dst)\n",
    "            run_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023088bd",
   "metadata": {},
   "source": [
    "CheckPTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce419d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# --- Settings ---\n",
    "df = pd.read_excel(\"./data/master.xlsx\")\n",
    "base_dir = Path(\"/Users/payamsadeghishabestari/temp_folder/audiometry\")\n",
    "df[\"PTA_L\"] = np.nan\n",
    "df[\"PTA_R\"] = np.nan\n",
    "pta_freqs = [500, 1000, 2000]\n",
    "\n",
    "# for subject in df[\"subject_ID\"].values:\n",
    "subject = \"erzw\"\n",
    "subj_dir = base_dir / subject   \n",
    "\n",
    "for hemi in [\"L\", \"R\"]:\n",
    "    files = [\n",
    "                f for f in subj_dir.glob(\"*.mat\")\n",
    "                if f.name.lower().startswith(f\"{subject.lower()} {hemi.lower()}\")\n",
    "            ]\n",
    "    if not files:\n",
    "        raise ValueError(f\"{subject} has missing audiometry files.\")\n",
    "\n",
    "    fname = files[0]\n",
    "    data = loadmat(fname)\n",
    "#         freqs = data[\"betweenRuns\"][\"var1Sequence\"][0][0][0]\n",
    "#         thrs  = data[\"betweenRuns\"][\"thresholds\"][0][0][0]\n",
    "#         order = np.argsort(freqs)\n",
    "#         freqs_sorted = freqs[order]\n",
    "#         thrs_sorted  = thrs[order]\n",
    "#         mask = np.isin(freqs_sorted, pta_freqs)\n",
    "#         if subject == \"typy\":\n",
    "#             mask = np.isin(freqs_sorted, [1000, 2000])\n",
    "\n",
    "#         if not mask.any():\n",
    "#             raise ValueError(f\"{subject} has missing frequencies.\")\n",
    "\n",
    "#         pta = thrs_sorted[mask].mean()\n",
    "#         df.loc[df[\"subject_ID\"] == subject, f\"PTA_{hemi}\"] = pta\n",
    "\n",
    "# df[\"PTA\"] = 0.5 * (df[\"PTA_L\"] + df[\"PTA_R\"])\n",
    "# df = df[['subject_ID', 'group', 'age', 'sex', 'PTA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f59e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1000,   250,   500,  2000,  6000, 12000,  4000,   125,  8000],\n",
       "      dtype=uint16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"betweenRuns\"][\"var1Sequence\"][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d69032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.25,  -1.75, -11.25, -12.75,   6.75,  18.  ,  -5.75, -10.  ,\n",
       "         3.75])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"betweenRuns\"][\"thresholds\"][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "396cd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad051e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Volumes/G_USZ_ORL$/Research/ANTINOMICS/data\")\n",
    "eeg_dir = data_dir / \"eeg\"\n",
    "audio_dir = data_dir / \"audiometry\"\n",
    "files = [f for f in eeg_dir.iterdir() if f.is_file() and f.name.endswith(\"_rest.vhdr\")]\n",
    "files = sorted(files, key=os.path.getctime)\n",
    "subject_tide_ids = [str(i) for i in range(70001, 70001 + len(files))]\n",
    "subject_antinomics_ids = [file.stem[:4] for file in files]\n",
    "subject_to_tide_map = dict(zip(subject_antinomics_ids, subject_tide_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5655cc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:11<00:00,  6.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for subject in tqdm(subject_antinomics_ids):\n",
    "    subject_audio_dir = audio_dir / subject\n",
    "    if subject_audio_dir.exists():\n",
    "        for fname in subject_audio_dir.iterdir():\n",
    "            for hemi in [\"L\", \"R\"]:\n",
    "                if fname.name.lower().startswith(f\"{subject.lower()} {hemi.lower()} ant\"):\n",
    "                    data = loadmat(fname)\n",
    "                    freqs = data[\"betweenRuns\"][\"var1Sequence\"][0][0][0]\n",
    "                    thrs  = data[\"betweenRuns\"][\"thresholds\"][0][0][0]\n",
    "                    order = np.argsort(freqs)\n",
    "                    freqs_sorted = freqs[order]\n",
    "                    thrs_sorted  = thrs[order]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 11.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "\n",
    "# The frequencies you want as columns\n",
    "target_freqs = [125, 250, 500, 1000, 2000, 4000, 6000, 8000, 12000]\n",
    "\n",
    "# Build all hemi-specific column names\n",
    "freq_cols = []\n",
    "for hemi in [\"L\", \"R\"]:\n",
    "    for f in target_freqs:\n",
    "        freq_cols.append(f\"{hemi}_{f} Hz\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for subject in tqdm(subject_antinomics_ids):\n",
    "    \n",
    "    subject_audio_dir = audio_dir / subject\n",
    "    tide_id = subject_to_tide_map.get(subject, np.nan)\n",
    "\n",
    "    # Create empty row for subject\n",
    "    row = {\"antinomics_id\": subject, \"tide_id\": tide_id}\n",
    "\n",
    "    # Initialize all possible columns with NaN so missing ones remain NaN\n",
    "    for col in freq_cols:\n",
    "        row[col] = np.nan\n",
    "\n",
    "    if subject_audio_dir.exists():\n",
    "        for fname in subject_audio_dir.iterdir():\n",
    "            for hemi in [\"L\", \"R\"]:\n",
    "                if fname.name.lower().startswith(f\"{subject.lower()} {hemi.lower()}\"):\n",
    "\n",
    "                    data = loadmat(fname)\n",
    "                    freqs = data[\"betweenRuns\"][\"var1Sequence\"][0][0][0]\n",
    "                    thrs  = data[\"betweenRuns\"][\"thresholds\"][0][0][0]\n",
    "\n",
    "                    # Sort\n",
    "                    order = np.argsort(freqs)\n",
    "                    freqs_sorted = freqs[order]\n",
    "                    thrs_sorted  = thrs[order]\n",
    "\n",
    "                    # Fill the corresponding hemi columns\n",
    "                    for f, thr in zip(freqs_sorted, thrs_sorted):\n",
    "                        f_int = int(f)\n",
    "                        col_name = f\"A{hemi}E_{f_int}\"\n",
    "                        if col_name in row:\n",
    "                            row[col_name] = thr\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Order columns\n",
    "df = df[[\"antinomics_id\", \"tide_id\"] + freq_cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
